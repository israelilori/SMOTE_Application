{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Last name: ILORI\n",
    "Date: 29-01-2020\n",
    "Approach:\n",
    "Target AUC: 0.825\n",
    "Achieved AUC: 0.87"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the datasets\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check first five observations of the data\n",
    "train_data.head(5)\n",
    "test_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check info of the data for missing values and shape \n",
    "train_data.info()\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data.describe()\n",
    "#test_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDA to look at the correlation between features in the data\n",
    "a = train_data.iloc[:,:9]\n",
    "corr_matrix = a.corr()\n",
    "plt.subplots(figsize=(10,6))\n",
    "sns.heatmap(corr_matrix, vmax=0.9, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature encoding for categorical values in the dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "number = LabelEncoder()\n",
    "train_data['gender'] = number.fit_transform(train_data['gender'].astype('str'))\n",
    "test_data['gender'] = number.fit_transform(test_data['gender'].astype('str'))\n",
    "train_data['device_type'] = number.fit_transform(train_data['device_type'].astype('str'))\n",
    "test_data['device_type'] = number.fit_transform(test_data['device_type'].astype('str'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = train_data.iloc[:,:9].values \n",
    "y = train_data.iloc[:,9].values\n",
    "test = test_data.iloc[:,:].values\n",
    "\n",
    "\n",
    "#X = xgb.DMatrix(X, y)\n",
    "#y = xgb.DMatrix(test)\n",
    "\n",
    "#Standardizing the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 2)\n",
    "\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "dim_x_train = X_train_scaled.reshape (X_train_scaled.shape[0],X_train_scaled.shape[1],1)\n",
    "dim_x_test = X_test_scaled.reshape(X_test_scaled.shape[0],X_test_scaled.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from imblearn.over_sampling import SMOTE\n",
    "import imblearn.over_sampling as imb\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "oversampler = imb.SMOTE(random_state=3)\n",
    "from imblearn.pipeline import Pipeline\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "k_values = [1, 2, 3, 4, 5, 6, 7]\n",
    "for k in k_values:\n",
    "# define pipeline\n",
    "    model = XGBClassifier()\n",
    "    over = SMOTE(sampling_strategy=0.3, k_neighbors=k)\n",
    "    under = RandomUnderSampler(sampling_strategy=0.2)\n",
    "    steps = [('over', over), ('under', under), ('model', model)]\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    \n",
    "X_train,y_train = oversampler.fit_sample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE\n",
    "y.shape, (y==1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "rcf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV( rcf,\n",
    "                   {'max_depth': [2,4,6],\n",
    "                    'n_estimators': [50,100,200]}, verbose=1)\n",
    "#Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}# Create a based model\n",
    "#rfc = RandomForestClassifier()\n",
    "#rfc = XGBRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rcf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting the models\n",
    "from sklearn.metrics import accuracy_score, f1_score, auc, roc_curve, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from xgboost.sklearn import XGBRFClassifier\n",
    "\n",
    "lr = LogisticRegression()\n",
    "#research on hyperparameter tuning\n",
    "#rfc = RandomForestClassifier(n_estimators = 1000, min_samples_split = 8, \n",
    " #                            min_samples_leaf = 3, max_depth = 50, max_features = 9, criterion = 'entropy')\n",
    "#xgb = XGBClassifier(n_estimators = 1600, min_samples_split = 10, \n",
    "  #                 min_samples_leaf = 2, max_depth = 15)\n",
    "xgb = XGBClassifier(n_estimators = 1000, min_samples_split = 10, \n",
    "                     min_samples_leaf = 1, max_depth = 10, max_features = 2)\n",
    "\n",
    "#rfc = RandomForestClassifier()\n",
    "\n",
    "#lr.fit(X_train, y_train)\n",
    "#rfc.fit(X_train, y_train)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "# calculate accuracy\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(metrics.f1_score(y_test, y_pred))\n",
    "print(metrics.roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_test == 1).sum(), (y_pred == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ROCAUC\n",
    "# Instantiate the visualizer with the classification model\n",
    "classes = [0,1]\n",
    "visualizer = ROCAUC(, classes=classes)\n",
    "\n",
    "visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "g = visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the roc curve\n",
    "from sklearn.metrics import accuracy_score, f1_score, auc, roc_curve, roc_auc_score\n",
    "fpr, tpr, thr = metrics.roc_auc_score(y_test, y_pred)\n",
    "metrics.roc_auc_score(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting on the test set\n",
    "#Use classes_ to get the two distinct classes\n",
    "\n",
    "#add a new column to the test data and call it test observations\n",
    "test_data2 = pd.read_csv('test.csv')\n",
    "    \n",
    "test_data2.insert(0, 'test_observations', range(1, 1 + len(test_data2)))\n",
    "\n",
    "test_data2['gender'] = number.fit_transform(test_data2['gender'].astype('str'))\n",
    "test_data2['device_type'] = number.fit_transform(test_data2['device_type'].astype('str'))\n",
    "\n",
    "\n",
    "pred_test = test_data2.iloc[:,1:]\n",
    "\n",
    "ac = scaler.transform(pred_test)\n",
    "#predictions = xgb.dump_model(ac)\n",
    "predictions = xgb.classes_\n",
    "\n",
    "#Save the outcome variable to a dataframe\n",
    "resultDf = pd.DataFrame(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where (y_pred == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resultDf = xgb.trees_to_dataframe()\n",
    "\n",
    "test_data3 = test_data2\n",
    "test_id = test_data3[\"test_observations\"]\n",
    "\n",
    "#Export to csv to get a report format for the outcome variable\n",
    "sub = pd.DataFrame()\n",
    "sub['test_observations'] = test_id\n",
    "sub['target'] = resultDf\n",
    "sub.to_csv('result.csv', index=False)\n",
    "\n",
    "result_data = pd.read_csv('result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
